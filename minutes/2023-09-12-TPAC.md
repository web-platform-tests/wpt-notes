# wpt TPAC 2023

# Matrix

https://app.element.io/#/room/#wpt:matrix.org

# Links

* Notes archive: https://github.com/web-platform-tests/wpt-notes/tree/master/minutes

* RFCs: https://github.com/web-platform-tests/rfcs

* Infra issues: https://github.com/web-platform-tests/wpt/issues?q=is%3Aopen+label%3Ainfra+-label%3Adependencies

## Agenda Items

Attendees: @jgraham @dontcallmedom @sideshowbarker @past @muodov @fscholz @keithamus @rakuco

### Introductions

### Call for Topics

 * Web Extensions testing
 * CI reliability
   -  Azure problems 
   -  WebDriver BiDi
 * Docker / GitHub
 * Reducing the number of open PRs
 * Dealing with existing intermittents
 * wptrunner / webdriver-bidi
 * Fuzzy annotations
 * Go through all the open RFC issues/PRs (size-to-fit)


### Web Extensions Testing

Maxim - Web Extensions group sees potential in automated testing. There was consensus that wpt would be a good place to try to implement this. It's still very early. Next steps would probably be using existing tooling to inject extensions. There's a discussion of how to structure the tests. Tests would be individual tiny extensions. Tooling should allow testing communication between web extensions, so harness would have to live outside the web extension code. Would require changes in WebDriver in order to inject the extension at runtime rather than requiring a browser restart. Still very early stage.

James - From the WPT side we'd need an API that installs/uninstalls an add-on, reports the status. Seems very plausible. Maybe we could add more capabilties later, but this seems like a good start. 

Sam - Can't select the popup with WebDriver even though it's web content in principle. 

Kiara - Why?

Sam - Some security concerns about webdriver being able to interact with popup.

Maxim - Browser vendors have some existing tools, which we could learn from. 

Mike - All browsers have some browser specific ways of running tests. For wpt we need something that will work cross browser. In terms of logistic requirements, you need to make sure you have someone who can review tests, because existing wpt contributors don't necessarily have the relevant domain knowledge.

Tim - Not sure that's a big problem.

Maxim - There does seem to be momentum in the web extensions group and people are willing to do this.

Kiara - Do we need existing people in wpt to do the reviews?

Mike - We can grant the necessary access. 

James - We need someone to come up with the WebDriver API extension points and do the actual implementation work. We can do the reviews and provide design feedback.

### CI Reliability

Sam - Don't know how much there is to say. wpt relies on Azure pipelines for mac and Windows. For macOS Ventura we've had a lot of problems with the tests machines just vanishing. This mostly affects the longer runs of Safari for the whole testsuite. Last we heard from Azure team, expected fix date is October. People are currently manually retrying failing runs, but that's not very scalable.

Panos - They promised a fix in August?

Sam - There are some improvements, but it's still happening a lot.

Maxim - Is there an alternative?

Sam - There are a small number that need investigation. A lot of CI providers have older macOS versions, but that won't work for STP. We also have relatively high capacity requirements. 

Panos - We did discuss trading off Edge and Safari runs.

Sam - The problem is the percentage of failures. The tradeoff makes more sense to add capacity for iOS and WebKit Test Runner runs.

James - Don't know of any alternatives apart from getting Apple to do the runs in-house and upload the results. Some disadvantages to doing that e.g. hard to investigate failures, hard to know what the setup is.doing that e.g. hard to investigate failures, hard to know what the setup is.

Sam - Flow is currently working like that.

Panos - Also Chrome for Android.

James - There are no more things we can do. Maybe automating re-runs of failed tests.

Panos - When we have mobile testing, this will become a bigger problem. We could wait until then to find an alternative, but for now we just hope they fix it.

James - Yes, if the problem continues we should look more seriously at alternatives.

Mike - Stuck PRs where checks aren't passing and also aren't failing yet. The way to get help is to ping @web-platform-tests/admins 

Tim - Also close + reopen

Mike - is that recommended?

Panos - We do that quite often. Maybe James can speak to the WebDriver BiDi issue.

James - If we look at the logs of failed checks we can see the particular issue. Closing the PR and reopening is the best we could have. On Azure rerunning jobs is doable, Taskcluster is more difficult for technical reasons, requires admin access. The WebDriver specific reason is taht when we run jobs we don't run every CI job. The sink task actually has to pass. In WebDriver BiDi we try to run all the affected tests. If a file changed that is a test, run the test. If we can statically detect that a file affects a test, run the test. If changing a python file, then any test could be affected. The stability jobs try to run all tests more than once. Stability jobs used to timeout for WebDriver because they would run every test 10 times. One option is to not run any tests if you change the fixture file. Another would be to figure out which tests should run, but it's not obvious that this should be easy or possible. An intermediate option would be to put a limit to the number of tests to select, say 100 tests. 

Sam - Maybe we could figure out the imports. Probably doesn't work.

James - due to how pytests works the right fix would need to find the entire dependency graph.

Panos - We want to make stability tests non-blocking.

James - That should be straightforward to implement. Until recently the Firefox stability check  was quite buggy for WebDriver changes, but that is now fixed. 

Panos - We have a backlog project on how to measure stability of the CI system, be we don't have concrete plans yet. If you have ideas please let us know.

James - An Azure related issue is that we treat the infrastructure tests as non-blocking. 

Sam - We don't have any way to notice that infra jobs are failing. We could in theory automatically create PRs based on the results of those tests in wpt.fyi runs. 

James - It sounds that in principle this should work. 

Sam - On Azure we also run Firefox and Chrome.

[discussion about what is actually run on Azure and why; c.f. https://github.com/web-platform-tests/wpt/pull/13911 adding Chrome & Firefox]

James - Not having macOS results in wpt.fyi might make it harder to auto-update metadata, the update script might decide that macOS as a configuration doesn't exist and so remove relevant metadata.

Sam - Depends on how we configure the metadata update.

James - Yes, maybe is we don't set os as a property it can update it would work out.

James - Have we got anything actionable?

Panos - We have ideas, but it's not clear if anything is ready to be prioritised. 

James - Maybe fixing the Chrome Stability Check to be non-blocking (#40990). Maybe also limiting the number of tests that we run when a WebDriver fixture changes.

ACTION - jgraham to file issue for WebDriver stability

### Docker / GitHub

James - We have discussed limitations of DockerHub. We can't have many admins, current workflow is quite manual. Also questions about whether we are still eligible for the free tier as an OSS project.

Panos - Ongoing discussion with Docker. Currently discussing technicalities, but it looks fairly promising.

James - If that works out we don't have a fire to put out. But we should investigate other container registries. Most obvious option would be GitHub. Looks like it should work, but someone needs to investigate in detail.

Panos - That seems like it would require an RFC, probably from the person doing the investigation.

James - I think we should try to do this in any case; current limitations of DockerHub do cause problems e.g. limited number of users in the org who can push images.

[break]

### Reducing the number of open PRs

Panos - Something that I keep thinking about. We have ~ a thousand open PRs. Many are Chromium exports. Still 400ish, down from 1200. There's a manual process that has been automated. It has a threshold of ~30 days. What about other non-Chromium PRs, specifically with DO Not Merge Yet labels?

Sam - How many Do Not Merge Yet labels are Chromium exports?

Should Chromium only create PRs once it's ready?

Panos - I think there's a practical reason for that. But I forget the details.

Sam - Wanting to be able to run against upstream CI.

Sometimes CLs are created just to run the tests, even if there's no intent to land it. 

Panos - Those are supposed to be auto-deleted. Please send me links to ones that aren't deleted.

Sam - [see matrix: "https://github.com/web-platform-tests/wpt/pull/16404 e.g. has an abandoned CL but isn't closed"]

James - Maybe the Chromium sync PRs should be draft PRs? Gecko doesn't have this problem because we don't create a PR until things are on autoland (but this has other problems).

Panos - I'll file an internal issue to make that change.

Panos - It seems like there should be low-hanging fruit here in terms of reducing the number of open PRs. Are there possible bugs to fix other than the Chromium exporter? We have a stream of people jumping on matrix asking for a merge of long-term open PRs.

Sam - It's hard to get people to pay attention to wpt PRs. They are more likely to look at vendor PRs.

Panos - Why is that?

James - Matches what their employer requries.

Panos - Another component is that WPT review requests are noisy (too many, too many reviewers assigned diffusing responsibility). Maybe we should be more strict about only having a single reviewer assigned at any point in time.

Sam - This is why we ended up assigning PRs to people (maybe 2018?). There's also a lot of desire from people working on standards to look at all the PRs coming in for the specs they edit. There are competing requirements and it's unclear how to reconcile these differences. Could split META.yml files so that we always select one person from "Maybe reviewers" list and everyone from "always notify" list. Most browser vendor systems either require you to know who to request a review from or request a review from everyone.

James - I think Servo did that at one point.

Martin - We don't have that anymore. It wasn't maintained.

Panos - Not a social reason.

Martin - We've talked about using CODEOWNERS

Sam - That adds everyone as a reviewer. It's used a bit for WebKit.

Panos - This change would only work if it would push people into doing things.

Sam - As far as we know people don't review because they don't feel like it's a priority for them or their managers. Changing the wpt infra won't fix that.

Adam - When the are multiple reviewers assigned I assume that someone else will look at it.

Panos - Our team gets reviews for which we don't necessarily have context.

AdamJam - Often understand the domain but don't have context on the specific tests.

James - I think if someone made the change Sam suggested then we'd land it, but there's a history of these changes having less impact than we hoped.

Adam - Can we have non-reviewer CCs?

Sam - No.

James - You're supposed to do that by @cc'ing people in comments, but we don't want to add additional comments because it annoys people who depend on GH notifications.

Panos - Seems like the export PRs are the low hanging fruit here.

Sam - Yes, but they are also not really causing any problems.

### Dealing with existing intermittents

James - Currently we don't have any way to tell if a stability failure is an existing problem or something introduced by the PR. We could handle the case of an added test (but don't). The result might be that people are inclined to ignore the results of other failures since they might be an existing problem.

Panos - I use the Show History button in wpt.fyi. This shows the results in the previous runs. Can be easy to tell if something is or isn't an intermittent. Gives a way to argue for this. Currenly hard to use. We have a GSoC student working on improving that. /flags on staging server has one for "Show New History". Same set of rows but with a better layout. Indicates when the results changed. Can click on the segement to get to the run where the staus changed. Currently still in development, but should be enabled by default in the next few weeks.

James - Would be really useful as an API; if we could ask this from the CI checks then we could just mark jobs as Waring rather than fail if the intermittents appear to already be on master.

Panos - Might be possible. Currently focused on landing the new frontend, but I think there's an API here that the frontend is used. If we could stop marking PRs as failed when there's a reasonable suspicion that the failure is intermittent I think that would make a big difference.

### wptrunner / webdriver-bidi

James - Getting close to being able to implement wptrunner on WebDriver BiDi, think basic test running functionality is there, some things needed by testdriver aren't there (especailly things defines by other specs); for Gecko we run some code in the chrome scope (via the Marionette executor), but could probably prototype a runner using WebDriver BiDi at this point. Bunch of reasons to do this: largest is that WebDriver can only talk to one window at a time, and everything is sync, so anything involving multiple frames/windows becomes incredibly hacky (top-level window ends up waiting on a test result, so frame has to tell top-level to say "hey do this action" in the "simple" case). e.g., if you want to check if something has happened in a cross-origin iframe it is much easier. One question is actual mechanics, who is going to work on it, and another question about how to support both BiDi and other implementations, and how to support other test features.

Sam - For test driver?

James - Yes, but also potentially if we add other means to do cross-origin messaging that doesn't work with WebDriver/etc. There is already precedent for not every vendor supporting every feature, with test driver support varying; Servo doesn't support any test driver stuff as far as I know. Don't know what WKTR does?

Sam - Kinda the same as Servo, but with a server process getting passed URLs.

James - We unofficially have a notion of Tier-1 browsers which are those used in Interop, and we'd like to make sure they can still run all the tests for features they actually support without running into problems with the harness itself.

Sam - Clearly we want webkit testrunner to be able to run tests, especially for iOS testing. I don't think there's any clear answer about the probability of reaching a point where webkit testrunner itself has bidi support. It's not very likely. If it doesn't we're limited to having testdriver things being implemented on top of internal js apis. This becomes a question of which features we're building that depend on bidi. Cross origin messaging might be possible in a way that's independent of bidi, but that depends on the exact API design.

James - The goal is to not stop having test runs. It is to have compatible implementations in every browser.

Sam - On the implementation side, BiDi test depend on contunuations in Python. Currently wptrunner is all sync. There are benefits to making the testrunner depend on continuations, but do we think there are other options?

James - I'm hoping that you could do it in a drop in way, since executors run in their own process.

Sam - We need a run loop. At that point it's easy to call async or sync things. 

James - I think it might be hard to reuse some of the existing code, but I haven't thought about this in detail. We might need to define a new set of base classes for the executor with async versions of the same lifecycle API/methods.

James - OK, so it sounds like the consenus is that this is worth prototyping, but we need to bear in mind the requirement that we can have non-webdriver based implementations. No specific plans, but it could be a good project for Outreachy or similar.

Mike - Have we had Outreachy contributions?

James - Yes, but via browser projects, wpt is not directly participating in these programmes.

### Fuzzy annotations

Martin - Would a patch be welcome to add difference levels to wpt output, for use in updating fuzzy annotations?

James - Yes.

### Open RFCs

https://github.com/web-platform-tests/rfcs/pulls

Panos - https://github.com/web-platform-tests/rfcs/pull/163 is waiting for input

James - Yes, I'll add some comments today.

James - https://github.com/web-platform-tests/rfcs/pull/117

Sam - Comments on the RFC about the more general case of tagging merges. Seems like there isn't much objection to moving them to a different ref namespace. Might just be waiting for implementation?

James - Does the RFC itself need to be updated? Yes, looks like it does.

James - Question might be who does the work. Foolip suggested this but will he have time to do the work?

Panos - I recall that maybe James Scott was interested in looking at this.

James - If we also change the merge_pr_ tags to be in their own namespace we'd also have to update the gecko sync, which uses them to match commits to PRs where possible. Not a blocker, but we'd need to know in advance.
