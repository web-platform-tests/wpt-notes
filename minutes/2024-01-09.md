# wpt RFCs/infra sync

* Notes archive: https://github.com/web-platform-tests/wpt-notes/tree/master/minutes

* RFCs: https://github.com/web-platform-tests/rfcs

* Infra issues: https://github.com/web-platform-tests/wpt/issues?q=is%3Aopen+label%3Ainfra+-label%3Adependencies

* Matrix: https://app.element.io/#/room/#wpt:matrix.org

## Agenda Items for Jan 9th, 2023

### origin-isolation tests need to be run in separate browsing context groups #23364

[Issue](https://github.com/web-platform-tests/wpt/issues/23364)

- weizhong - some tests need to be run in new browser context. We should look into addressing this
- jgraham - currently have close-after-done flag. So that the window is closed before each test. If that is set, should create a new browsing context group. Implementations can choose not to do it for slightly better performance. There might be a restart-before flag. But that might be overkill. If that's what people really want, we could do it. Currently only possible in the INI file. Could change it be in the metadata of the test
- weizhong - we are always doing this. Only works for harness tests
- jgraham - Agree it works for harness tests. Don't think we do it for ref tests. Closing the test window and opening a new with webdriver should be enough. If we want to guarantee isolation over performance, we need more metadata. If we want some tests to indicate they want a separate browsing group, they should have some flag in the attributes to indicate it needs a browsing context group. The default config, it should happen anyway. But non default config, you would need to read the flag and do something different. Example HTTPS is one where the flag is in the file name.
- weizhong - will go check with developers what kind of problems they are facing. Then see if there's a solution we can do for them


### wpt.live long term

jcscottiii- Google have been maintaining the project. Ownership has moved at Google; there's some additional overhead associated with that. Want to understand how people think about this long term.

@jgraham - It's nice to have when it works. Some tests do not work. Would be helpful to see usage stats. Not something I use a lot but I know others use. Sometimes people will provide the URL.

@jbedard - I will check on the Apple side if someone uses it.


Action Item: jcscottiii - Get usage stats for next meeting

### Parallel tests using shared resources (clipboard)

[Issue] https://bugzilla.mozilla.org/show_bug.cgi?id=1866605

- @jgraham - Multiple tests are trying to write and read from the clipboard. Given the clipboard is a global resource, can lead to race condition. Is this a problem other vendors are running into? 
- @jbedard - We don't have a great solution to this. The clipboard is probably the obvious resource, probably other resources have the same problem.
- @jgraham - This is why we didn't run parallel tests on the same machine. Two cases we should care about. Where any implementation is going to run into the problem (e.g clipboard). I wonder if there's some lock we should have for these resources.
- @jbedard - we have 8-16 tests running at the same time. Most tests don't have the problem. Having some mark in the file would probably be the right way to do this. An idea: Exclude all the tests that need global resources and move them all to one machine. Run those test serially.
- weizhong  - Wouldn't running those tests serially be good enough
- @jbedard - If there aren't many yes
- @jgraham - I think the knowing isn't essential. But if you do know why, you can avoid problems in the future. Example. Any test that relies on GROUP UKNOWN 1
- @jbedard  - We need two solutions: A way to mark them and a way to make sure they never run in parallel
- @jgraham - sounds like no one has a solution but we can write up a RFC
- @jbedard - agreed

Action item:
- [ ] Draft a RFC - unassigned


### Keep test metadata in sync with test when subtests are deleted or renamed.

[Issue] https://github.com/web-platform-tests/wpt/issues/43499

weizhong - How are we currently doing this
jgraham - not every config is guaranteed to run the same subtests. (on mobile might not see subtests, on desktop might see a lot). Maybe give a status for each subtests on each platform. How we currently handle this in Gecko, when we import new tests, we run every tests on every configuration we have. Then the metadata update has a full flag that will delete metdata automically. Does not handle renames. We ignore subtests that didn't happen in a certain config
weizhong - We use baselines. 
jgraham - We don't require anything from developers. We don't store metadata if the tests passes everywhere. Since the default is PASS. When we do the INI update, we record the subtests that we see anywhere. Only update if there was an unexpected result. If a developer renames a test, could temporarily leave orphan metadata
weizhong - Could check for a clean up and see if that is good enough

Action items:
 weizhong to investigate and provide update

### RFC 163 Update

- jcscottiii - Wanted to give an update about what I have in store for that RFC. Creating a new manifest file along side the existing Manifest file. It will be generated at the same time as the existing one.
- jgraham - Seems fine. We should look into how to consolidate all the existing metadata tooling. But for now that is fine.
 
